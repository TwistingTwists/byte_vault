---
slug: "forevervm-minimal"
title: "Minimal example of ForeverVM"
date: 2025-03-01T00:00:00+00:00
draft: true
authors: [abeeshake] 
tags: [ python, gvisor ]
---


# Building ForeverVM

## Introduction

In the rapidly evolving landscape of Large Language Models (LLMs), one of the most powerful capabilities is code generation and execution. However, executing untrusted code generated by LLMs poses significant security risks. This blog post explores a solution: a gVisor-based Python REPL that provides a secure, isolated environment for executing untrusted code in LLM-based workflows.

## The Challenge of Code Execution in LLM Applications

LLMs like GPT-4, Claude, and others have demonstrated remarkable capabilities in generating functional code across various programming languages. This has led to the development of "agentic" applications where LLMs can:

1. Generate code to solve specific problems
2. Execute that code to obtain results
3. Analyze the results and iterate on the solution
4. Interact with external systems and APIs

However, executing code generated by LLMs introduces several challenges:

- **Security Risks**: LLM-generated code might contain vulnerabilities, either accidentally or through prompt injection attacks
- **Resource Management**: Unconstrained execution could lead to resource exhaustion
- **Stateful Execution**: Many tasks require maintaining state between multiple code executions
- **Isolation**: Code execution needs to be isolated from the host system and other users' code

## Introducing gVisor-based Python REPL

Our solution addresses these challenges through a multi-layered security approach:

1. **Docker Containerization**: Provides basic isolation from the host system
2. **gVisor Sandbox**: Adds an additional security layer by intercepting and filtering system calls
3. **TCP Interface**: Limits interaction to a simple TCP API, reducing attack surface
4. **Session Management**: Maintains stateful execution while ensuring isolation between sessions

### Architecture Overview

The system consists of several key components:

1. **TCP Server**: A Python TCP server that accepts code execution requests and maintains stateful sessions
2. **Docker Container**: Provides containerization for the Python environment
3. **gVisor Runtime**: Adds an additional layer of isolation by intercepting and filtering system calls

### How It Works

1. The server runs inside a Docker container with gVisor's runsc runtime
2. Clients connect to the server via TCP and send Python code to execute
3. The server executes the code in a session-specific environment
4. Results are returned to the client
5. Sessions persist between requests, allowing for stateful execution

## Setting Up Your Own Secure Python REPL

### Prerequisites

- Docker
- gVisor (runsc)

### Installation Steps

1. Install gVisor:
   ```bash
   sudo apt-get update && \
   sudo apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg

   # Install runsc
   curl -fsSL https://gvisor.dev/archive.key | sudo gpg --dearmor -o /usr/share/keyrings/gvisor-archive-keyring.gpg
   echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/gvisor-archive-keyring.gpg] https://storage.googleapis.com/gvisor/releases release main" | sudo tee /etc/apt/sources.list.d/gvisor.list > /dev/null
   sudo apt-get update && sudo apt-get install -y runsc
   ```

2. Configure Docker to use gVisor:
   ```bash
   sudo runsc install
   sudo systemctl restart docker
   ```

3. Clone the repository:
   ```bash
   git clone https://github.com/username/gvisor-based-python-repl.git
   cd gvisor-based-python-repl
   ```

4. Run the server:
   ```bash
   ./run.sh
   ```

## Integrating with LLM Applications

### Client-Side Integration

To integrate this secure Python REPL with your LLM application, you'll need to:

1. Establish a TCP connection to the server
2. Send Python code generated by your LLM
3. Receive and process the execution results
4. Optionally maintain session state for multi-step workflows

Here's a simple Python example:

```python
import socket
import json

def send_code_to_repl(code, session_id=None):
    # Connect to the server
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.connect(("localhost", 8000))

    # Skip initial greeting
    length_bytes = sock.recv(4)
    message_length = int.from_bytes(length_bytes, byteorder='big')
    sock.recv(message_length)

    # Prepare request
    request = {
        "code": code
    }
    if session_id:
        request["session_id"] = session_id

    # Send request
    request_json = json.dumps(request)
    request_bytes = request_json.encode('utf-8')
    length = len(request_bytes)
    sock.sendall(length.to_bytes(4, byteorder='big'))
    sock.sendall(request_bytes)

    # Receive response
    length_bytes = sock.recv(4)
    message_length = int.from_bytes(length_bytes, byteorder='big')
    response_bytes = sock.recv(message_length)
    response = json.loads(response_bytes.decode('utf-8'))

    sock.close()
    return response

# Example usage
response = send_code_to_repl("print('Hello, world!')")
print(response["output"])

# Use the session_id for subsequent requests
session_id = response["session_id"]
response = send_code_to_repl("x = 42\nprint(f'x = {x}')", session_id)
print(response["output"])
```

### LLM Workflow Integration

Here's how you might integrate this into an LLM-based workflow:

1. User provides a problem description
2. LLM generates Python code to solve the problem
3. Your application sends the code to the secure REPL
4. Execution results are returned to the LLM
5. LLM analyzes the results and iterates if needed

This approach allows for powerful agentic workflows while maintaining security.

## Security Considerations

While this system provides strong isolation, it's important to understand its limitations:

- Side-channel attacks might still be possible
- Resource exhaustion could affect container performance
- New vulnerabilities in gVisor or Docker could compromise security

Regular updates and security audits are recommended.

## Use Cases

This secure Python REPL is particularly useful for:

1. **Educational Platforms**: Allow students to execute code safely
2. **AI Coding Assistants**: Enable LLMs to execute and test generated code
3. **Data Analysis Workflows**: Run data processing scripts in a secure environment
4. **Automated Code Testing**: Test user-submitted code without security risks
5. **Interactive Documentation**: Create interactive code examples that users can modify and run

## Conclusion

The gVisor-based Python REPL provides a secure foundation for executing untrusted code in LLM-based workflows. By combining Docker containerization with gVisor's sandboxing capabilities, it offers a robust solution to the security challenges of code execution in AI applications.

As LLMs continue to evolve and become more integrated into software development workflows, tools like this will be essential for balancing the power of code generation with the necessary security constraints.

Whether you're building an AI coding assistant, an educational platform, or any application that involves executing untrusted code, this approach provides a practical and secure solution.
Footer
