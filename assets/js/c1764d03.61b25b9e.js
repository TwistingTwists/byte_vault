"use strict";(self.webpackChunkbytevault=self.webpackChunkbytevault||[]).push([[447],{1160:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"how-to-solve-reverse-proxy-performance-issues-in-caddy-server-a-300-performance-boost-using-unix-sockets","metadata":{"permalink":"/byte_vault/blog/how-to-solve-reverse-proxy-performance-issues-in-caddy-server-a-300-performance-boost-using-unix-sockets","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-12-23-caddy-performance.mdx","source":"@site/blog/2024-12-23-caddy-performance.mdx","title":"Caddy Reverse Proxy Performance: 300% Boost with Unix Sockets","description":"A recent GitHub issue  #6751  in the Caddy server repository revealed an interesting performance bottleneck when using multiple layers of reverse proxying. Here\'s what was discovered and how it was resolved.","date":"2024-12-23T00:00:00.000Z","tags":[{"inline":false,"label":"Performance","permalink":"/byte_vault/blog/tags/performance","description":"Blog posts related to improving and understanding performance."},{"inline":false,"label":"Caddy","permalink":"/byte_vault/blog/tags/caddy","description":"caddy config and tuning"}],"readingTime":3.965,"hasTruncateMarker":true,"authors":[{"name":"Abhishek Tripathi","title":"Curiosity brings awareness.","url":"https://github.com/TwistingTwists","page":{"permalink":"/byte_vault/blog/authors/abeeshake"},"socials":{"x":"https://x.com/twistin456","github":"https://github.com/TwistingTwists"},"imageURL":"https://github.com/TwistingTwists.png","key":"abeeshake"}],"frontMatter":{"slug":"how-to-solve-reverse-proxy-performance-issues-in-caddy-server-a-300-performance-boost-using-unix-sockets","title":"Caddy Reverse Proxy Performance: 300% Boost with Unix Sockets","date":"2024-12-23T00:00:00.000Z","authors":["abeeshake"],"tags":["performance","caddy"]},"unlisted":false,"nextItem":{"title":"1brc - same tricks across languages","permalink":"/byte_vault/blog/1brc-same-tricks-across-languages"}},"content":"A recent GitHub issue  [#6751](https://github.com/caddyserver/caddy/issues/6751)  in the Caddy server repository revealed an interesting performance bottleneck when using multiple layers of reverse proxying. Here\'s what was discovered and how it was resolved.\\n\\n{/* truncate */}\\n\\n## The Problem\\n\\nA user reported significant performance degradation when implementing multiple layers of reverse proxies in Caddy v2.8.4. The setup consisted of a chain of reverse proxies:\\n\\n- Port 8081: Serving static files\\n- Port 8082: Proxying to 8081\\n- Port 8083: Proxying to 8082\\n- Port 8084: Proxying to 8083\\n\\nWhen testing with a 1000MB file download, the performance metrics showed a clear pattern of degradation:\\n\\n### Multi-Threading Performance Impact\\n\\n- Direct file server (8081): ~300 Mbps with 5 threads\\n- First proxy layer (8082): ~60 Mbps with 5 threads\\n- Second proxy layer (8083): ~16 Mbps with 5 threads\\n- Third proxy layer (8084): ~16 Mbps with 5 threads\\n\\nWhat made this particularly interesting was that the server\'s CPU usage remained surprisingly low (1-5%), suggesting that the bottleneck wasn\'t in processing power.\\n\\n## The Investigation\\n\\nThe investigation, led by Caddy maintainers including Matt Holt, involved:\\n\\n1. Gathering system metrics\\n2. Analyzing CPU and memory profiles\\n3. Testing different network configurations\\n4. Examining kernel settings\\n\\n### Table 1: System Metrics\\n\\n\\n| **Commands**                                 | **Why It Is Relevant to Debugging**                                                                                               | **Output and Conclusion**                                                                                                                                                                                                                                                |\\n| -------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\\n| `ulimit -a`                                  | Checks system limits such as maximum number of open files and other resource constraints that could impact performance.           | No bottlenecks identified in file descriptors or resource limits.                                                                                                                                                                                                        |\\n| `sysctl -p`                                  | Confirms network-related kernel parameters such as buffer sizes, default queuing discipline, and TCP congestion control settings. | <br/>`net.core.rmem_max = 2097152`<br/>`net.core.wmem_max = 2097152`<br/>`net.core.default_qdisc = fq`<br/>`net.ipv4.tcp_congestion_control = bbr`<br/><br/> Settings were optimized for high-speed networking.<br />TCP congestion control was correctly set to`bbr`. |\\n| General hardware specs (CPU, RAM, NIC, etc.) | baseline hardware information                                                                                                     | Verified adequate resources (1 Core Ryzen 5950X, 1024MB RAM, 10Gbps NIC). No resource-related constraints.                                                                                                                                                               |\\n\\n---\\n\\n### Table 2: Profile Analysis\\n\\n\\n| **Commands**                                                  | **Why It Is Relevant to Debugging**                                                                | **Output and Conclusion**                                                                          |\\n| --------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |\\n| Attempted to collect goroutine profiles                       | Helps identify bottlenecks or inefficiencies in goroutines that may be causing performance issues. | Could not identify significant bottlenecks in goroutines.                                          |\\n| Accessed CPU Profile via browser                              | Provides CPU usage details to determine if high CPU usage is a factor affecting performance.       | No high CPU usage detected. CPU load was between 1-5%.                                             |\\n| `wget http://127.0.0.1:2019/debug/pprof/profile?seconds=1000` | Downloads detailed CPU profiles for offline analysis.                                              | Profiles downloaded successfully. Further analysis confirmed no CPU bottlenecks or inefficiencies. |\\n| Collected heap profiles                                       | Helps analyze memory usage and potential leaks in the application.                                 | Memory usage was within acceptable limits, with no indication of memory leaks.                     |\\n\\n---\\n\\n### Table 3: Network Testing\\n\\n\\n| **Commands**                                                                           | **Why It Is Relevant to Debugging**                                                          | **Output and Conclusion**                                               |\\n| -------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |\\n| Tests from multiple locations (Singapore, Los Angeles, Seoul)                          | Evaluates network performance across different regions to identify geographical bottlenecks. | Performance was consistent across all regions.                          |\\n| Tests with different file sizes (100MiB, 1000MiB)                                      | Determines if performance issues are related to file size or payload.                        | No significant performance variance with different file sizes.          |\\n| `curl -o /dev/null http://host.domain:port/1000MiB`                                    | Single-threaded test evaluates download performance under minimal concurrency.               | acceptable network speed                                                |\\n| `echo 1 1 1 1 1 \\\\| xargs -n1 -P5 curl -s -o /dev/null http://host.domain:port/1000MiB` |                                                                                              | Multi-threaded test assesses network performance under concurrent load. |\\n\\n\\n---\\n\\n### Table 4: Kernel Analysis\\n\\n\\n| **Commands**                                       | **Why It Is Relevant to Debugging**                                                                  | **Output and Conclusion**                                         |\\n| -------------------------------------------------- | ---------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- |\\n| Checked systemd service file settings              | Confirms that the maximum number of open files is sufficient for high-concurrency workloads.         | Verified`LimitNOFILE=1048576`. No issues found.                   |\\n\\n\\n## The Solution\\n\\nThe breakthrough came when testing with Unix sockets instead of TCP connections. By modifying the Caddyfile to use Unix sockets for inter-process communication, the performance issues were completely resolved. Here\'s what the optimized configuration looked like:\\n\\n```\\n:8081 {\\n    bind 0.0.0.0 unix//dev/shm/8081.sock\\n    file_server browse\\n    root * /opt/www\\n}\\n\\n:8082 {\\n    bind 0.0.0.0 unix//dev/shm/8082.sock\\n    reverse_proxy unix//dev/shm/8081.sock\\n}\\n\\n:8083 {\\n    bind 0.0.0.0 unix//dev/shm/8083.sock\\n    reverse_proxy unix//dev/shm/8082.sock\\n}\\n\\n:8084 {\\n    reverse_proxy unix//dev/shm/8083.sock\\n}\\n```\\n\\n## Key Takeaways\\n\\n1. TCP connection overhead can significantly impact performance in multi-layer reverse proxy setups\\n2. Unix sockets provide a more efficient alternative for local inter-process communication\\n3. Low CPU usage doesn\'t always mean optimal performance - network stack overhead can be the bottleneck\\n4. When dealing with multiple local reverse proxies, consider using Unix sockets instead of TCP connections"},{"id":"1brc-same-tricks-across-languages","metadata":{"permalink":"/byte_vault/blog/1brc-same-tricks-across-languages","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-12-22-1brc-common-learnings.mdx","source":"@site/blog/2024-12-22-1brc-common-learnings.mdx","title":"1brc - same tricks across languages","description":"The 1 Billion Row Challenge (1BRC) is a programming challenge focused on processing a large dataset of temperature measurements. If you\'re unfamiliar with it, you can learn more from these resources: 1 and 2.","date":"2024-12-22T00:00:00.000Z","tags":[{"inline":false,"label":"Performance","permalink":"/byte_vault/blog/tags/performance","description":"Blog posts related to improving and understanding performance."}],"readingTime":2.16,"hasTruncateMarker":true,"authors":[{"name":"Abhishek Tripathi","title":"Curiosity brings awareness.","url":"https://github.com/TwistingTwists","page":{"permalink":"/byte_vault/blog/authors/abeeshake"},"socials":{"x":"https://x.com/twistin456","github":"https://github.com/TwistingTwists"},"imageURL":"https://github.com/TwistingTwists.png","key":"abeeshake"}],"frontMatter":{"slug":"1brc-same-tricks-across-languages","title":"1brc - same tricks across languages","date":"2024-12-22T00:00:00.000Z","authors":["abeeshake"],"tags":["performance"]},"unlisted":false,"prevItem":{"title":"Caddy Reverse Proxy Performance: 300% Boost with Unix Sockets","permalink":"/byte_vault/blog/how-to-solve-reverse-proxy-performance-issues-in-caddy-server-a-300-performance-boost-using-unix-sockets"}},"content":"The 1 Billion Row Challenge (1BRC) is a programming challenge focused on processing a large dataset of temperature measurements. If you\'re unfamiliar with it, you can learn more from these resources: [1](https://github.com/gunnarmorling/1brc) and [2](https://www.morling.dev/blog/1brc-results-are-in/).\\n\\nThis is a cheatsheet  of optimisations done for 1brc challenges. It tries to summarise and put the optimisations in perspective.\\n\\n{/* truncate */}\\n\\n### Data encoding / parsing\\n\\n\\n| Trick                                         | Outcome                                                                                     | Note                                                                                                                                                 |\\n| :---------------------------------------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |\\n| converting contents of file as string: don\'t! | [~10% perf](https://github.com/gunnarmorling/1brc/discussions/57#discussioncomment-8153186) | Don\'t convert the contents of the file to`String`. Simply process raw bytes.                                                                         |\\n| parsing float values<br />                    |                                                                                             | parsing after assuming only one place after decimal.                                                                                                 |\\n| parsing integer                               |                                                                                             | [Branchless Programming via Bit Manipulation](https://youtu.be/EFXxXFHpS0M?t=1255)<br /> this is not generalizable                                   |\\n| parsing the city name (finding`;` separator)  |                                                                                             | If the data looks like`Tokio;13.4` and we want to find `;`<br/><br/>using 8 operations, you can find `;`.<br /><br /><br />SWAR = SIMD as a register |\\n\\n### Reading files from disk\\n\\n\\n| Trick                                                                                                                                  | Outcome                                                                                     | Note                                                                                                                                                                                                                    |\\n| ---------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| Reading in chunks[golang](https://www.bytesizego.com/blog/one-billion-row-challenge-go#:~:text=Reading%20file%3A%20Read%20in%20chunks) | [~10% perf](https://github.com/gunnarmorling/1brc/discussions/57#discussioncomment-8153186) |                                                                                                                                                                                                                         |\\n| mmap                                                                                                                                   |                                                                                             | [mmap the input file. Split input based on core count and run it with a thread per core.](https://github.com/gunnarmorling/1brc/discussions/57#discussioncomment-8041416)<br/><br/>mmap is an unsafe operation in Rust. |\\n\\n### Float handling\\n\\n\\n| Trick                                        | Outcome                                                                                                         | Notes |\\n| ---------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- | ------- |\\n| Don\'t do floating point operations. Use int. | [20% speed gains](https://github.com/gunnarmorling/1brc/discussions/57#discussioncomment-8024568)               |       |\\n| Use fixed size integers instead of float     | [~10% gain in golang](https://benhoyt.com/writings/go-1brc/#:~:text=Solution%204%3A%20fixed%20point%20integers) |       |\\n\\n### The Hashmap - simpler hash function\\n\\n\\n| Trick                                                                                                                                                                                                                        | Outcome                                                                                                                                                                                                                        | Note                                                                                                                                                                                                                                                                                                                                                                                        |\\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| [Fixed Size hash table 10k](https://github.com/gunnarmorling/1brc/discussions/57#:~:text=Treat%20the%20first%20eight%20bytes%20of%20the%20name%20as%20a%20hash%20key%20into%20a%20fixed%20size%2010k%20item%20hash%20table.) | [~40% gain - the custom hash table cuts down the time from 41.3 seconds to 22.1s.](https://benhoyt.com/writings/go-1brc/#:~:text=the%20custom%20hash%20table%20cuts%20down%20the%20time%20from%2041.3%20seconds%20to%2022.1s.) | How to resolve collisions?<br /><br />- Find first unoccupied slot<br />- <br />[if hash collide, goto next empty slot algorithm](https://benhoyt.com/writings/go-****1brc/#:~:text=It%E2%80%99s%20a%20simple%20implementation%20that%20uses%20the%20FNV%2D1a%20hash%20algorithm%20with%20linear%20probing%3A%20if%20there%E2%80%99s%20a%20collision%2C%20use%20the%20next%20empty%20slot.) |\\n| Hash key - Integer, not String                                                                                                                                                                                               | [4x gain in a different competition](https://youtu.be/SVw9nKfVPx4?t=501)                                                                                                                                                       | the time is spent in`Hashmap.get`.<br /> Not in 1brc, but in [other context](https://www.youtube.com/watch?v=SVw9nKfVPx4&t=501s), Hashmap.get was the bottleneck. hence this optimisation makes a lot of difference there, not in 1brc.                                                                                                                                                     |\\n\\n### With OS threads and parallelism - go brr!\\n\\n\\n| Trick                                                        | Outcome                                                                                                                                                                                                                                  | Notes                                                     |\\n| -------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------- |\\n| address the go routine + rust tokio task + erlang processes? | [~ 4-6x gains](https://benhoyt.com/writings/go-1brc/#:~:text=Processing%20the%20input%20file%20in%20parallel%20provides%20a%20huge%20win%20over%20r1%2C%20taking%20the%20time%20from%201%20minute%2045%20seconds%20to%2022.6%20seconds.) | biggest gains are obtained by utilizing OS threads fully! |"}]}}')}}]);